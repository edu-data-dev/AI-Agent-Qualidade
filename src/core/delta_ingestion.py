"""
M√≥dulo de Ingest√£o Delta - Processa apenas arquivos alterados
=============================================================

Este m√≥dulo implementa a funcionalidade de aprendizado cont√≠nuo,
processando apenas os arquivos que foram modificados (git diff).

Ideal para integra√ß√£o CI/CD onde apenas deltas s√£o ingeridos.
"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Tuple
from datetime import datetime

from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import PromptTemplate
from dotenv import load_dotenv

# Carregar vari√°veis de ambiente
load_dotenv()

# ================================
# CONFIGURA√á√ïES
# ================================
CHROMA_PERSIST_DIR = "./chroma_db"
EMBEDDING_MODEL = "text-embedding-ada-002"
TRANSLATION_MODEL = "gpt-4o-mini"
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200


# ================================
# PROMPT DE TRADU√á√ÉO (REUTILIZADO)
# ================================
CODE_TO_RULE_PROMPT = PromptTemplate(
    template="""Voc√™ √© um analista de neg√≥cios especializado em extrair regras de neg√≥cio de c√≥digo-fonte.

Analise o seguinte trecho de c√≥digo Python e extraia TODAS as regras de neg√≥cio (expl√≠citas e impl√≠citas).

C√≥digo:
{code}

Para cada regra identificada, retorne no formato:
"Regra [N]: [Descri√ß√£o clara da regra em portugu√™s]"

Regras:""",
    input_variables=["code"]
)


# ================================
# FUN√á√ïES AUXILIARES
# ================================
def get_file_type(file_path: str) -> str:
    """Determina o tipo do arquivo (code ou doc)."""
    if file_path.endswith('.py'):
        return 'code'
    elif file_path.endswith('.md'):
        return 'doc'
    else:
        return 'unknown'


def load_document(file_path: str) -> str:
    """Carrega o conte√∫do de um arquivo."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"‚ùå Erro ao carregar {file_path}: {e}")
        return ""


def translate_code_to_rules(code: str, llm: ChatOpenAI) -> str:
    """Traduz c√≥digo Python em regras de neg√≥cio usando LLM."""
    try:
        chain = CODE_TO_RULE_PROMPT | llm
        response = chain.invoke({"code": code})
        return response.content
    except Exception as e:
        print(f"‚ùå Erro na tradu√ß√£o: {e}")
        return code


def process_single_file(file_path: str, llm: ChatOpenAI, splitter: CharacterTextSplitter) -> Tuple[List[str], str]:
    """Processa um √∫nico arquivo e retorna os chunks e o tipo."""
    print(f"  üìÑ Processando: {file_path}")
    
    file_type = get_file_type(file_path)
    content = load_document(file_path)
    
    if not content:
        return [], file_type
    
    # Se for c√≥digo, traduz primeiro
    if file_type == 'code':
        print(f"    üîÑ Traduzindo c√≥digo em regras de neg√≥cio...")
        content = translate_code_to_rules(content, llm)
    
    # Divide em chunks
    chunks = splitter.split_text(content)
    
    # Adiciona metadados aos chunks
    chunks_with_metadata = []
    for i, chunk in enumerate(chunks):
        metadata_prefix = f"[Fonte: {os.path.basename(file_path)} | Tipo: {file_type} | Chunk: {i+1}]\n"
        chunks_with_metadata.append(metadata_prefix + chunk)
    
    print(f"    ‚úÖ {len(chunks_with_metadata)} chunks criados")
    return chunks_with_metadata, file_type


# ================================
# FUN√á√ÉO PRINCIPAL DE INGEST√ÉO DELTA
# ================================
def process_changed_files(
    changed_files: List[str],
    db_path: str = CHROMA_PERSIST_DIR,
    force_recreate: bool = False
) -> Dict[str, int]:
    """
    Processa apenas os arquivos alterados e atualiza o banco vetorial.
    
    Args:
        changed_files: Lista de caminhos dos arquivos alterados
        db_path: Caminho do banco de dados ChromaDB
        force_recreate: Se True, recria o DB do zero
        
    Returns:
        Dicion√°rio com estat√≠sticas da ingest√£o
    """
    print("\n" + "="*60)
    print("üß† C√âREBRO DE QA - INGEST√ÉO DELTA")
    print("="*60)
    print(f"‚è∞ In√≠cio: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üìÇ Banco de dados: {db_path}")
    print(f"üìù Arquivos a processar: {len(changed_files)}")
    print("="*60 + "\n")
    
    # Estat√≠sticas
    stats = {
        'total_files': len(changed_files),
        'processed_files': 0,
        'code_chunks': 0,
        'doc_chunks': 0,
        'total_chunks': 0,
        'errors': 0
    }
    
    # Inicializar componentes
    print("üîß Inicializando componentes LangChain...")
    llm = ChatOpenAI(model=TRANSLATION_MODEL, temperature=0.1)
    embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)
    splitter = CharacterTextSplitter(
        separator="\n\n",
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP
    )
    
    # Carregar ou criar banco vetorial
    if force_recreate or not os.path.exists(db_path):
        print("üÜï Criando novo banco de dados vetorial...")
        vector_store = None
    else:
        print("üìö Carregando banco de dados existente...")
        try:
            vector_store = Chroma(
                persist_directory=db_path,
                embedding_function=embeddings
            )
            print(f"   ‚úÖ Banco carregado: {vector_store._collection.count()} documentos existentes")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erro ao carregar banco: {e}")
            print("   üÜï Criando novo banco...")
            vector_store = None
    
    # Processar cada arquivo alterado
    all_chunks = []
    all_metadatas = []
    
    print(f"\nüì• Processando {len(changed_files)} arquivo(s)...")
    
    for file_path in changed_files:
        # Ignorar arquivos que n√£o existem mais (deletados)
        if not os.path.exists(file_path):
            print(f"  ‚è≠Ô∏è  Ignorando arquivo deletado: {file_path}")
            continue
        
        # Ignorar arquivos de tipos n√£o suportados
        file_type = get_file_type(file_path)
        if file_type == 'unknown':
            print(f"  ‚è≠Ô∏è  Ignorando tipo n√£o suportado: {file_path}")
            continue
        
        try:
            chunks, chunk_type = process_single_file(file_path, llm, splitter)
            
            if chunks:
                # Criar metadados para cada chunk
                for chunk in chunks:
                    all_chunks.append(chunk)
                    all_metadatas.append({
                        'source': file_path,
                        'type': chunk_type,
                        'timestamp': datetime.now().isoformat()
                    })
                
                # Atualizar estat√≠sticas
                stats['processed_files'] += 1
                if chunk_type == 'code':
                    stats['code_chunks'] += len(chunks)
                else:
                    stats['doc_chunks'] += len(chunks)
                
        except Exception as e:
            print(f"  ‚ùå Erro ao processar {file_path}: {e}")
            stats['errors'] += 1
    
    stats['total_chunks'] = len(all_chunks)
    
    # Adicionar chunks ao banco vetorial
    if all_chunks:
        print(f"\nüíæ Adicionando {len(all_chunks)} chunks ao banco vetorial...")
        
        try:
            if vector_store is None:
                # Criar novo banco
                vector_store = Chroma.from_texts(
                    texts=all_chunks,
                    embedding=embeddings,
                    metadatas=all_metadatas,
                    persist_directory=db_path
                )
                print("   ‚úÖ Novo banco criado com sucesso!")
            else:
                # Adicionar ao banco existente
                vector_store.add_texts(
                    texts=all_chunks,
                    metadatas=all_metadatas
                )
                print("   ‚úÖ Chunks adicionados ao banco existente!")
            
        except Exception as e:
            print(f"   ‚ùå Erro ao salvar no banco: {e}")
            stats['errors'] += 1
    else:
        print("\n‚ö†Ô∏è  Nenhum chunk foi gerado. Nada para adicionar ao banco.")
    
    # Relat√≥rio final
    print("\n" + "="*60)
    print("üìä RELAT√ìRIO DA INGEST√ÉO DELTA")
    print("="*60)
    print(f"‚úÖ Arquivos processados: {stats['processed_files']}/{stats['total_files']}")
    print(f"üì¶ Total de chunks: {stats['total_chunks']}")
    print(f"   ‚îî‚îÄ C√≥digo: {stats['code_chunks']} chunks")
    print(f"   ‚îî‚îÄ Docs:   {stats['doc_chunks']} chunks")
    if stats['errors'] > 0:
        print(f"‚ùå Erros: {stats['errors']}")
    print(f"‚è∞ Fim: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60 + "\n")
    
    return stats


# ================================
# FUN√á√ÉO DE DETEC√á√ÉO GIT DIFF
# ================================
def get_changed_files_from_git(base_ref: str = "HEAD^", compare_ref: str = "HEAD") -> List[str]:
    """
    Detecta arquivos alterados usando git diff.
    
    Args:
        base_ref: Refer√™ncia base (ex: HEAD^, main)
        compare_ref: Refer√™ncia de compara√ß√£o (ex: HEAD)
        
    Returns:
        Lista de caminhos de arquivos alterados
    """
    import subprocess
    
    try:
        print(f"üîç Detectando altera√ß√µes: {base_ref}..{compare_ref}")
        
        result = subprocess.run(
            ['git', 'diff', '--name-only', base_ref, compare_ref],
            capture_output=True,
            text=True,
            check=True
        )
        
        files = [f.strip() for f in result.stdout.split('\n') if f.strip()]
        
        # Filtrar apenas .py e .md
        relevant_files = [f for f in files if f.endswith(('.py', '.md'))]
        
        print(f"   ‚úÖ {len(relevant_files)} arquivo(s) Python/Markdown alterado(s)")
        for f in relevant_files:
            print(f"      - {f}")
        
        return relevant_files
        
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Erro ao executar git diff: {e}")
        return []


# ================================
# MAIN (para testes)
# ================================
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Ingest√£o Delta - Processa apenas arquivos alterados")
    parser.add_argument('--files', nargs='+', help='Lista de arquivos para processar')
    parser.add_argument('--git-diff', action='store_true', help='Detectar arquivos via git diff')
    parser.add_argument('--base', default='HEAD^', help='Refer√™ncia base para git diff')
    parser.add_argument('--recreate', action='store_true', help='Recriar banco do zero')
    
    args = parser.parse_args()
    
    # Determinar arquivos a processar
    if args.git_diff:
        files = get_changed_files_from_git(base_ref=args.base)
    elif args.files:
        files = args.files
    else:
        print("‚ùå Erro: Especifique --files ou --git-diff")
        sys.exit(1)
    
    if not files:
        print("‚ö†Ô∏è  Nenhum arquivo para processar")
        sys.exit(0)
    
    # Executar ingest√£o delta
    stats = process_changed_files(
        changed_files=files,
        force_recreate=args.recreate
    )
    
    # Exit code baseado em sucesso
    sys.exit(0 if stats['errors'] == 0 else 1)
